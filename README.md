# Compressions-Algorithms
In this digital age, efficient data storage and transmission are crucial, necessitating effective data compression algorithms. Huffman, LZW, and Arithmetic coding are three widely used methods, each with their unique characteristics and use-cases. This report offers a concise comparison between these algorithms based on key performance indicators: compression speed, memory usage, and compression ratio. The objective is to elucidate their pros and cons, assisting in the selection of the appropriate algorithm depending on specific requirements.

## Huffman Coding
### Theory Behind Huffman Coding
The core idea behind Huffman coding is to minimize the total length of a message (representing some form of data) that is encoded in binary. It achieves this by assigning shorter code words to symbols that occur more frequently in the message.

Huffman coding starts with a data set (e.g., text, image, etc.) and calculates the frequency of each symbol (e.g., letter, pixel, etc.). The algorithm then constructs a priority queue (or a binary heap), where each node contains a symbol and its frequency.

The two nodes (symbols) with the smallest frequencies are repeatedly removed from the priority queue, combined into a new node, and reinserted back into the priority queue. This new node has a frequency that is the sum of the frequencies of the two original nodes, and it becomes the parent node of the two original nodes in the Huffman tree. This process is repeated until only one node remains in the priority queue, which becomes the root of the Huffman tree.

The Huffman code for each symbol is then generated by traversing the Huffman tree from the root to the leaf node corresponding to the symbol, adding a '0' for each left branch and a '1' for each right branch.


## LZW Coding
### Theory Behind LZW Coding
The LZW algorithm is a lossless data compression algorithm that was developed by Abraham Lempel, Jacob Ziv, and Terry Welch. It belongs to a family of dictionary-based compression algorithms that includes the earlier LZ77 and LZ78 algorithms.

The fundamental idea behind LZW, and dictionary-based compression algorithms in general, is to replace repeating sequences of data with shorter representations.

In LZW, this is achieved by maintaining a dictionary of sequences that have been encountered previously in the input data. As data is read, if the current data sequence (including the current symbol) is found in the dictionary, it continues reading. When it encounters a sequence not in the dictionary, it outputs the code for the longest prefix that was in the dictionary, adds a new entry to the dictionary for the encountered sequence, and then starts a new sequence with the current symbol.


## LZW Coding
### Theory Behind Arithmetic Coding
Arithmetic coding is based on the principles of information theory. It operates by maintaining a range of probabilities for all possible symbols in the input data. The range is then successively subdivided as input symbols are encoded, with the range corresponding to the current symbol being used as the new overall range.

The probabilities are often estimated using frequency tables derived from the input data, which means that the coding is adaptive and able to efficiently encode data where the probabilities of different symbols vary.


